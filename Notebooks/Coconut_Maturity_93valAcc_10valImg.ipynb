{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNeisQMfclYS"
      },
      "source": [
        "# Coconut Categorization based on Maturity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37Ngv6NZxHVx"
      },
      "source": [
        "**References**: \n",
        "\n",
        "1.   NVIDIA DLI - Fundamentals of Deep Learning - Assesment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POWjDjFhoUVV"
      },
      "source": [
        "## About this Notebook and Dataset\n",
        "In this notebook we will train a model to categorize coconuts based on maturity. Dataset used is the following:\n",
        "\n",
        " ``` Nambisan, Dr Hemalatha ; M K , Dr Rajesh (2021), “Coconut”, Mendeley Data, V1, doi: 10.17632/mmc345tfjw.1 ``` \n",
        " \n",
        " The dataset contains images of coconuts belonging different categories based on coconut maturity. Categories in the dataset are tender, one,two, three, forur, five and six, corresponding to week number . Thus we will need  an output layer of 7 neurons to do the categorization successfully. We also need to compile the model with `categorical_crossentropy`, as we have more than two categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eppOFHl3oUVY"
      },
      "source": [
        "## Load ImageNet Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvPYqt6ooUVY"
      },
      "source": [
        "We can start with a model pretrained on ImageNet. Load the model with the correct weights, set an input shape, and choose to remove the last layers of the model. Remember that images have three dimensions: a height, and width, and a number of channels. Because these pictures are in color, there will be three channels for red, green, and blue. We are implementing transfer learning here. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpasdEYHoUVb",
        "outputId": "b8f86e08-735a-4e0e-8f30-32c65c5106dd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js5sKOfcoUVe"
      },
      "source": [
        "## Freeze Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwCWevtJoUVf"
      },
      "source": [
        "Freezing the base model so that all the learning from the ImageNet dataset does not get destroyed in the initial training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "whGtg2OhoUVf"
      },
      "outputs": [],
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VgmBhFYoUVg"
      },
      "source": [
        "## Add Layers to Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xBD8iw0oUVh"
      },
      "source": [
        "Now it's time to add layers to the pretrained model. Pay close attention to the last dense layer and make sure it has the correct number of neurons to classify the different types of fruit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HLtitdnAoUVi"
      },
      "outputs": [],
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(7, activation = 'softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create model\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3T1B5vuoUVj",
        "outputId": "d8cd4921-be35-4298-9400-b8916bc82129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,718,279\n",
            "Trainable params: 3,591\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQx5Q9C_oUVj"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMn962UQoUVk"
      },
      "source": [
        "Now it's time to compile the model with loss and metrics options. Remember that we're training on a number of different categories, rather than a binary classification problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "btUAd_U5oUVl",
        "outputId": "f35003c2-ca5e-421e-f135-49b961b74f5c"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam', loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tLzK9aBoUVm"
      },
      "source": [
        "## Augment the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOfuyARBoUVm"
      },
      "source": [
        "If you'd like, try to augment the data to improve the dataset. Feel free to look at [notebook 04a](04a_asl_augmentation.ipynb) and [notebook 05b](05b_presidential_doggy_door.ipynb) for augmentation examples. There is also documentation for the [Keras ImageDataGenerator class](https://keras.io/api/preprocessing/image/#imagedatagenerator-class). This step is optional, but it may be helpful to get to 92% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MY7lSJ1AoUVm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        samplewise_center=True,  # set each sample mean to 0\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False) # we don't expect Bo to be upside-down so we will not flip vertically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xLmtyJOw3UX",
        "outputId": "07065d81-4e2d-4cc3-d61c-393494764088"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiFfh9RAoUVn"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjLeTYicoUVn"
      },
      "source": [
        "Now it's time to load the train and validation datasets. Pick the right folders, as well as the right `target_size` of the images (it needs to match the height and width input of the model you've created)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iQ7JQKAoUVo",
        "outputId": "dddad69f-0fcc-434f-b9aa-49205fa5ac4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 787 images belonging to 7 classes.\n",
            "Found 140 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory(\"DATA\\\\coconuts\\\\coconut_dataset\\\\train\",\n",
        "                                       target_size=(224, 224), \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode=\"categorical\")\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen.flow_from_directory(\"DATA\\\\coconuts\\\\coconut_dataset\\\\val\", \n",
        "                                      target_size=(224, 224), \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox3FTEdloUVo"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD7VyUKHoUVp"
      },
      "source": [
        "Time to train the model! Pass the `train` and `valid` iterators into the `fit` function, as well as setting the desired number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "US102AMboUVp",
        "outputId": "995c8fc4-b727-41e3-8d16-247b23cff65e"
      },
      "outputs": [
        {
          "ename": "Error",
          "evalue": "Session cannot generate requests",
          "output_type": "error",
          "traceback": [
            "Error: Session cannot generate requests",
            "at S.executeCodeCell (c:\\Users\\parva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
            "at S.execute (c:\\Users\\parva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
            "at S.start (c:\\Users\\parva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
            "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
            "at t.CellExecutionQueue.executeQueuedCells (c:\\Users\\parva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
            "at t.CellExecutionQueue.start (c:\\Users\\parva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
          ]
        }
      ],
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ZOrxn5oUVq"
      },
      "source": [
        "## Unfreeze Model for Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwaf5BI6oUVr"
      },
      "source": [
        "If you have reached needed validation accuracy already, this next step is optional. If not,  fine tune the model with a very low learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPp-zb0YoUVr"
      },
      "outputs": [],
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Compile the model with a low learning rate\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001),\n",
        "              loss = keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5uuK7PToUVs"
      },
      "outputs": [],
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0O6PF6HoUVs"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBVM9SU6oUVt"
      },
      "source": [
        "To improve validation accuracy, you may want to go back and either run more epochs of training, or adjust your data augmentation. \n",
        "\n",
        "Once you are satisfied with the validation accuracy, evaluate the model by executing the following cell. The evaluate function will return a tuple, where the first value is your loss, and the second value is your accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w0D_bg9oUVu"
      },
      "outputs": [],
      "source": [
        "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqdfHwPkfnPx"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UCSvGWwfmze"
      },
      "outputs": [],
      "source": [
        "model.save('SavedModels\\\\coconut_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "727EvqMAf0HD"
      },
      "source": [
        "## Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63lUUw55fzpH"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('SavedModels\\\\coconut_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbxYceHDG0Do"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Coconut_Maturity_93valAcc_10valImg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
