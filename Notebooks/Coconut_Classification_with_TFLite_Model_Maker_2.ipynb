{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Flower classification with TensorFlow Lite Model Maker with TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDABAblytltI"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/lite/codelabs/flower_classification/ml/Flower_Classification_with_TFLite_Model_Maker.ipynb\">      \n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/lite/codelabs/flower_classification/ml/Flower_Classification_with_TFLite_Model_Maker.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "Model Maker library simplifies the process of adapting and converting a TensorFlow neural-network model to particular input data when deploying this model for on-device ML applications.\n",
        "\n",
        "This notebook shows an end-to-end example that utilizes this Model Maker library to illustrate the adaption and conversion of a commonly-used image classification model to classify flowers on a mobile device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "To run this example, we first need to make a copy of this notebook. Click on \"Copy to Drive\" at the top of this notebook. Then we need to install serveral required packages, including Model Maker package that in github [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cv3K3oaksJv",
        "outputId": "90c6d812-d91c-4872-8830-1aac449bdd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 34.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 41.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 25.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 30.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 46 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 48.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 46.3 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTa1Ytr2-e1u",
        "outputId": "4647019b-d5d3-47d8-f4e5-a97fad505722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKRaYHABpob5"
      },
      "source": [
        "## Simple End-to-End Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZZ5DHXotaW"
      },
      "source": [
        "### Get the data path\n",
        "\n",
        "Let's get some images to play with this simple end-to-end example. Hundreds of images is a good start for Model Maker while more data could achieve better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jz5x0JoskPv"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/drive/MyDrive/coconut_dataset/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55MR6i6nuDm"
      },
      "source": [
        "You could replace `image_path` with your own image folders. As for uploading data to colab, you could find the upload button in the left sidebar shown in the image below with the red rectangle. Just have a try to upload a zip file and unzip it. The root file path is the current path.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/download.tensorflow.org/models/tflite/screenshots/model_maker_image_classification.png\" alt=\"Upload File\" width=\"800\" hspace=\"100\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRNv_mloS89"
      },
      "source": [
        "If you prefer not to upload your images to the cloud, you could try to run the library locally following the [guide](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) in github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VDriAdsowu"
      },
      "source": [
        "### Run the example\n",
        "The example just consists of 4 lines of code as shown below, each of which representing one step of the overall process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahtcO86tZBL"
      },
      "source": [
        "1.   Load input data specific to an on-device ML app. Split it to training data and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lANoNS_gtdH1",
        "outputId": "df029bbe-351c-4f5c-89c0-15c856aa1ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Load image with size: 929, num_label: 7, labels: five, four, one, six, tender, three, two.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Load image with size: 929, num_label: 7, labels: five, four, one, six, tender, three, two.\n"
          ]
        }
      ],
      "source": [
        "data = DataLoader.from_folder(image_path)\n",
        "train_data, test_data = data.split(0.9)\n",
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9IWyIztuRF"
      },
      "source": [
        "2. Customize the TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRXMZbrwtyRD",
        "outputId": "85b09e46-f109-46c2-d22f-ffe740ae0e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2_1 (Hub  (None, 1280)             3413024   \n",
            " KerasLayerV1V2)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,421,991\n",
            "Trainable params: 8,967\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 655s 28s/step - loss: 1.6741 - accuracy: 0.4198 - val_loss: 0.9493 - val_accuracy: 0.7742\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 520s 23s/step - loss: 0.9848 - accuracy: 0.7677 - val_loss: 0.7114 - val_accuracy: 0.9247\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 523s 23s/step - loss: 0.7934 - accuracy: 0.8709 - val_loss: 0.6784 - val_accuracy: 0.9462\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 520s 23s/step - loss: 0.7343 - accuracy: 0.9158 - val_loss: 0.6627 - val_accuracy: 0.9355\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 514s 23s/step - loss: 0.7098 - accuracy: 0.9130 - val_loss: 0.6524 - val_accuracy: 0.9462\n"
          ]
        }
      ],
      "source": [
        "model = image_classifier.create(train_data, validation_data=validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzb5Hl8kLmM",
        "outputId": "1d4d4408-0fc7-49ed-c3cf-4975a578b3f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2_1 (Hub  (None, 1280)             3413024   \n",
            " KerasLayerV1V2)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,421,991\n",
            "Trainable params: 8,967\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU2fDr-t2Ya"
      },
      "source": [
        "3. Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQr02VxJt6Cs",
        "outputId": "f5a116c9-4ec5-4ccd-a467-3c492164fae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 153s 20s/step - loss: 0.7079 - accuracy: 0.8925\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZw9zU8t84y"
      },
      "source": [
        "4.  Export to TensorFlow Lite model.\n",
        "You could download it in the left sidebar same as the uploading part for your own use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb-eIzfluCoa",
        "outputId": "361a52ba-ad6f-4366-f562-424ceea43e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbcclpkfl/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpbcclpkfl/assets\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpje2nqhh0/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpje2nqhh0/labels.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: /content/drive/MyDrive/SavedModels/4_Mar_Default_80_10_10_Acc89/model.tflite\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: /content/drive/MyDrive/SavedModels/4_Mar_Default_80_10_10_Acc89/model.tflite\n"
          ]
        }
      ],
      "source": [
        "model.export(export_dir='/content/drive/MyDrive/SavedModels/4_Mar_Default_80_10_10_Acc89')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyju1qc_v-wy"
      },
      "source": [
        "5. Download the trained model by clicking on the folder icon on the left hand side. Right-click on \"model.tflite\" and select download. Or run the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7hSmJsgWM0Lp",
        "outputId": "993933d8-6562-4c56-88ba-93ab55da8dad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4821bf21-07e6-4098-a40a-2eb1b2a4e5f5\", \"model.tflite\", 4013936)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/SavedModels/4_Mar_Default_80_10_10_Acc89/model.tflite') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QujcbgibNR1e"
      },
      "source": [
        "After this simple 5 steps, we can now continue to the next step in the [codelab](https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android-beta/#2).\n",
        "\n",
        "For a more comprehensive guide to TFLite Model Maker, please refer to this [notebook](https://colab.sandbox.google.com/github/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/image_classification.ipynb) and its [documentation](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Coconut_Classification_with_TFLite_Model_Maker_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}